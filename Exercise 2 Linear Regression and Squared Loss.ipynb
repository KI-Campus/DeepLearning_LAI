{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wbu80HmSJo-y"
   },
   "source": [
    "# Deep Learning\n",
    "## Exercise 2 - Machine Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GM2CKzjbJo_D"
   },
   "source": [
    "### 1. Linear Regression\n",
    "Implement a linear regression (the `lin_reg` function) with __PyTorch__ to fit a line, $h(x) = w_0 + w_1 x$,  to a set of points generated using the `generate_data` function as defined below. In particular, find $w_0$ and $w_1$ such that the sum of squares error, $\\sum_i ||h(x_i) - y_i||^2$, is minimized.\n",
    "\n",
    "For this task, use tensor operations, `torch.*` and `torch.linalg.inv` to compute the solution via matrix inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "deletable": false,
    "editable": false,
    "id": "018EU5W8Jo_F",
    "outputId": "4e45e63e-4f0e-411c-b148-4be1cb8554c8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def generate_data(f, spread, x_start, x_end, delta=1):\n",
    "    \"\"\"Generate a number of data points from f with some spread.\"\"\"\n",
    "    x = torch.arange(x_start, x_end, delta)\n",
    "    y = f(x) + (torch.rand(*x.shape) - 0.5) * spread\n",
    "    return x.unsqueeze(-1), y\n",
    "\n",
    "# generate some points\n",
    "w_gt = torch.tensor([2, 3], dtype=torch.float)\n",
    "f = lambda x: w_gt[0] + w_gt[1] * x\n",
    "x, y = generate_data(f, spread=5, x_start=0, x_end=10, delta=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot the points\n",
    "plt.plot(x, y, marker='.', linewidth=0)\n",
    "\n",
    "# plot f (orange)\n",
    "plt.plot(x, f(x), 'o', linewidth=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def lin_reg(X, y):\n",
    "    \"\"\"\n",
    "    Return the exact linear regression line, i.e. the weights which minimize the loss.\n",
    "\n",
    "    Input values:\n",
    "        - tensor X = [[x_0], ..., [x_n]], shape=(n, 1): the x-values of the data points\n",
    "        - tensor y = [y_0, ..., y_n], shape=(n,): the y-values of the data points\n",
    "\n",
    "    Return:\n",
    "        - tensor w = [w_0, w_1] such that w_0 is the bias and w_1 is the slope. Recall h(x) = w_0 + w_1 * x.\n",
    "    \"\"\"\n",
    "    # ToDo: Remove dummy and implement this function\n",
    "    w = torch.tensor([0,0], dtype=torch.float)\n",
    "    return w\n",
    "\n",
    "# perform linear regression\n",
    "w = lin_reg(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def lin_reg(X, y):\n",
    "    \"\"\"\n",
    "    Return the exact linear regression line, i.e. the weights which minimize the loss.\n",
    "\n",
    "    Input values:\n",
    "        - tensor X = [[x_0], ..., [x_n]], shape=(n, 1): the x-values of the data points\n",
    "        - tensor y = [y_0, ..., y_n], shape=(n,): the y-values of the data points\n",
    "\n",
    "    Return:\n",
    "        - tensor w = [w_0, w_1] such that w_0 is the bias and w_1 is the slope. Recall h(x) = w_0 + w_1 * x.\n",
    "    \"\"\"\n",
    "    X = torch.cat([torch.ones_like(X), X], axis=1)\n",
    "    X_dagger = torch.linalg.inv((X.T @ X)) @ X.T\n",
    "    w = X_dagger @ y\n",
    "    return w\n",
    "\n",
    "w = lin_reg(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'computed w:\\t{w.tolist()}')\n",
    "print(f'actual w:\\t{w_gt.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# plot the points\n",
    "plt.plot(x, y, marker='.', linewidth=0)\n",
    "\n",
    "# plot f (orange)\n",
    "plt.plot(x, f(x), 'o', linewidth=5)\n",
    "\n",
    "# plot the regression line (black dashed)\n",
    "plt.plot(x, w[0] + w[1] * x, 'k--', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sqared Loss\n",
    "\n",
    "Compute the **Empirical Loss (Training Error)** of your hypothesis.\n",
    "\\begin{equation}\n",
    "\\mathcal{L} = \\frac{1}{n}\\sum_{i=1}^{n} l(h, x_i, y_i)\n",
    "\\end{equation}\n",
    "where $l(h, x_i, y_i) = (y_i - h(x_i))^2$, i.e. squared loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def squaredLoss(hX, y):\n",
    "    \"\"\"\n",
    "    Return the squared loss, i.e. L2 Loss, of the linear regression.\n",
    "\n",
    "    Input values:\n",
    "        - tensor fX = [h(x_0), ..., h(x_n)], shape=(n, ): your hypothesis\n",
    "        - tensor y = [y_0, ..., y_n], shape=(n,): the y-values of the data points\n",
    "\n",
    "    Return:\n",
    "        - float loss\n",
    "    \"\"\"\n",
    "    # ToDo: Remove dummy and compute the square loss\n",
    "    loss = 0.\n",
    "    return loss\n",
    "\n",
    "# ToDo: Remove dummy and compute h(x) for the linear regression\n",
    "hX = torch.zeros_like(x)\n",
    "loss = squaredLoss(hX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def squaredLoss(hX, y):\n",
    "    \"\"\"\n",
    "    Return the squared loss, i.e. L2 Loss, of the linear regression.\n",
    "\n",
    "    Input values:\n",
    "        - tensor fX = [h(x_0), ..., h(x_n)], shape=(n, ): your hypothesis\n",
    "        - tensor y = [y_0, ..., y_n], shape=(n,): the y-values of the data points\n",
    "\n",
    "    Return:\n",
    "        - float loss\n",
    "    \"\"\"\n",
    "    loss = 1./hX.shape[0] * ( hX - y ).pow(2).sum().item()\n",
    "    return loss\n",
    "\n",
    "hX = w[0] + w[1]*x.flatten()\n",
    "loss = squaredLoss(hX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(f'squared loss = {loss:.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_ML_Basics.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:dl_lai]",
   "language": "python",
   "name": "conda-env-dl_lai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "767px",
    "left": "97px",
    "top": "139px",
    "width": "173px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
