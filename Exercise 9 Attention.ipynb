{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saItxTU2Vs9p"
   },
   "source": [
    "# Deep Learning\n",
    "## Exercise 9 - Attention Mechanism\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ7rrn4GQm05"
   },
   "source": [
    "### 1. Sentiment Classification with Soft Attention\n",
    "Recall that we have implemented a simple LSTM based sentimental classification model in the 5th exercise. Now we want to use all hidden states of LSTM layer via attention scores. We will use the same data and task setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly get the data\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "from torchtext import data, datasets, vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 0\n",
    "data_directory = './data'\n",
    "debugging = False #This can be set to True, if you want to test your implementation on a smaller subset\n",
    "\n",
    "\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "max_length = 200   # we want the maximum words in each text instance to be 200.\n",
    "max_vocab = 20000  # We want the vocabulary size not to exceed 20000.\n",
    "\n",
    "# define a function to preprocess and tokenize raw text input\n",
    "tokenizer = data.get_tokenizer('basic_english')\n",
    "def text_tokenizer(entry):\n",
    "    entry = re.sub('<\\w{1,2} />', ' ', entry) #replace <br /> and similar\n",
    "    entry = re.sub(r'[^\\w\\s]', ' ', entry) #remove any non-space or non-word characters\n",
    "    entry = re.sub(r'\\s+', ' ', entry) #replace multiple spaces by one space\n",
    "    tokens = tokenizer(entry)\n",
    "    return tokens\n",
    "\n",
    "# read the dataset, the first call also downloads the dataset. Split the training_data into training and validation\n",
    "train_set, test_set = datasets.IMDB(root=data_directory)\n",
    "train_set = list(train_set)\n",
    "test_set = list(test_set)\n",
    "\n",
    "\n",
    "if debugging: \n",
    "    train_labels = [l for l,t in train_set]\n",
    "    test_labels = [l for l, t in test_set]\n",
    "    train_set, _ = train_test_split(train_set, train_size=0.2, stratify=train_labels, random_state=random_seed)\n",
    "    test_set, _ = train_test_split(test_set, train_size=0.2, stratify=test_labels, random_state=random_seed)\n",
    "\n",
    "train_labels = [l for l,t in train_set]\n",
    "train_set, val_set = train_test_split(train_set, train_size=0.7, stratify=train_labels, random_state=random_seed)\n",
    "\n",
    "# build the vocabulary from the training data\n",
    "counter = Counter()\n",
    "for label, text in train_set:\n",
    "    tokens = text_tokenizer(text)\n",
    "    counter.update(tokens)\n",
    "    \n",
    "vocabulary = vocab.vocab(OrderedDict(counter.most_common()[:max_vocab]))\n",
    "special_tokens = ['<unk>', '<pad>']\n",
    "for i, tok in enumerate(special_tokens):\n",
    "    vocabulary.insert_token(tok, i)\n",
    "vocabulary.set_default_index(vocabulary['<unk>'])\n",
    "\n",
    "# build the train, validation and test dataloaders\n",
    "def collate_fn(batch):\n",
    "    labels, indexes = [], []\n",
    "    for label, text in batch:\n",
    "        labels.append(1 if label =='pos' else 0)\n",
    "        \n",
    "        tokens = text_tokenizer(text)\n",
    "        indexes += [torch.tensor([vocabulary[t] for t in tokens][:max_length])]\n",
    "    labels = torch.tensor(labels)\n",
    "    padded_indices = pad_sequence(indexes, padding_value=vocabulary['<pad>'], batch_first=True)\n",
    "        \n",
    "    return labels, padded_indices\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True, \n",
    "                              collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "val_dataloader = DataLoader(val_set, batch_size=32, shuffle=True, \n",
    "                              collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=False, \n",
    "                              collate_fn=collate_fn, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gPv0AVrQm07"
   },
   "source": [
    "#### 1. Build an LSTM with attention\n",
    "\n",
    "Reuse your code for the 5th exercise and add an attention mechanism. Specifically, you need to:\n",
    "* Compute the soft attention scores by the dot product of each hidden state and the last hidden state. \n",
    "* Compute a context vector by the weighted sum of all hidden states.\n",
    "* Apply a dropout layer with $p=0.3$ on the context vector.\n",
    "* Use the context vector to predict the label, instead of the original final state.\n",
    "\n",
    "$$Context = \\sum_{i=0}^{L}\\alpha_{i}  h_i, \\; \\text{where} \\\\\n",
    "\\alpha_{i} = \\frac{e_{sim(h_{L}, h_{i})}}{\\sum_{j}(e^{sim(h_{L}, h_{j})})} \\\\\n",
    "sim(a, b) = a \\cdot b    \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#ToDo: Implement an LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFF_8S8PQm07",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class AttentionSentimentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionSentimentClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocabulary), 100, padding_idx=vocabulary['<pad>'])\n",
    "        self.rnn = nn.LSTM(100, 200, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(400, 1)\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "        self.classify = nn.Sigmoid()\n",
    "        self.softm = nn.Softmax(1)\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        hidden, (last_hid, last_cell) = self.rnn(embedded)\n",
    "        last_hid = torch.cat((last_hid[0], last_hid[1]), -1) #Since we are using a bidirectional LSTM\n",
    "        last_hid = last_hid.unsqueeze(-1)                    #we need to concatenate these two\n",
    "\n",
    "        sims = torch.bmm(hidden,last_hid).squeeze(-1)\n",
    "        attention = self.softm(sims)\n",
    "        attention = attention.unsqueeze(-2)\n",
    "        context = torch.bmm(attention, hidden)  \n",
    "        drop_context = self.dropout(context)\n",
    "        linear = self.fc(drop_context)\n",
    "        output = self.classify(linear)\n",
    "        \n",
    "        return output.flatten(), attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train your model\n",
    "\n",
    "Train your model as in the 5th exercise (use binary cross-entropy loss and the adam optimizer, train for a maximum of 20 epochs and implement early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#ToDo: Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKxdsAPbJjpE",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(num_epochs, model, loss_funtion, optimizer, train_loader, val_loader, break_criterium, model_name):\n",
    "    best_val_loss = 100000\n",
    "    no_improve=0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for labels, indices in tqdm(train_loader, desc='Train Iter', ascii=True):\n",
    "            output, _ = model(indices)\n",
    "            loss = loss_function(output, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        acc, val_loss = evaluate(model, val_loader, loss_function)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improve = 0\n",
    "            torch.save(model.state_dict(), f'{model_name}.pt')\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        print(f\"Epoch {epoch} \\t Loss {val_loss:.5f} \\t Accuracy {acc:.5f}\")\n",
    "        if no_improve >= break_criterium:\n",
    "            model.load_state_dict(torch.load(f'{model_name}.pt'))\n",
    "            break\n",
    "                \n",
    "def evaluate(model, test_loader, loss_function):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_entries = 0\n",
    "    cum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for labels, indices in tqdm(test_loader, desc='Test Iter', ascii=True):\n",
    "            output, _ = model(indices)\n",
    "            preds = (output>0.5).int()\n",
    "            correct += (preds == labels).sum()\n",
    "            total_entries += labels.shape[0]\n",
    "            cum_loss += loss_function(output, labels.float()).item()\n",
    "    return correct/total_entries, cum_loss/len(test_loader)\n",
    "    \n",
    "ASC = AttentionSentimentClassifier()\n",
    "loss_function = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(ASC.parameters())\n",
    "train(15, ASC, loss_function, optimizer, train_dataloader, val_dataloader, 5, 'ASC') \n",
    "print(evaluate(ASC, test_dataloader, loss_function))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualize or print the attention\n",
    "\n",
    "Visualize or print the attention scores of a test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#ToDo: Visualize the attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "#Find a sentence with a reasonable length\n",
    "sample_sents = [entry for entry in test_set if 5 < len(text_tokenizer(entry[1])) < 25 ]\n",
    "print(sample_sents)\n",
    "sentence = sample_sents[0]\n",
    "print(sentence)\n",
    "tokens = text_tokenizer(sentence[1])\n",
    "token_ids = torch.tensor([[vocabulary[token] for token in tokens]])\n",
    "print(tokens)\n",
    "print(token_ids)\n",
    "\n",
    "#Get the attention scores\n",
    "output, attention = ASC(token_ids)\n",
    "print(attention.shape)\n",
    "\n",
    "print(f'Prediction: {output.item():.4f}')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.bar(range(len(tokens)), attention.detach().flatten(), tick_label=tokens)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "import numpy as np\n",
    "def to_html(word, importance):\n",
    "  def _get_color(attr):\n",
    "    # clip values to prevent CSS errors (Values should be from [-1,1])\n",
    "    attr = max(-1, min(1, attr))\n",
    "    if attr > 0:\n",
    "        hue = 120\n",
    "        sat = 75\n",
    "        lig = 100 - int(50 * attr)\n",
    "    else:\n",
    "        hue = 0\n",
    "        sat = 75\n",
    "        lig = 100 - int(-40 * attr)\n",
    "    return \"hsl({}, {}%, {}%)\".format(hue, sat, lig)\n",
    "  color = _get_color(importance)\n",
    "  tag = '<mark style=\"background-color: {color}; opacity:1.0; \\\n",
    "                    line-height:1.75\"><font color=\"black\"> {word}\\\n",
    "                    </font></mark>'.format(\n",
    "            color=color, word=word)\n",
    "  return tag\n",
    "res = ''.join(to_html(word, att) for word, att in zip(tokens, attention.detach().flatten()))\n",
    "display_html(res, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwC7xKD-5YpC"
   },
   "source": [
    "### 2. Sentiment Classification with Transformer\n",
    "Recall that we have implemented a very simple LSTM based sentimental classification model in the 5th exercise. Now it is the time to replace the LSTM module with the Transformer. Again we will use the same IMDB dataset and the transformer implementation from `torch.nn`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define the Model\n",
    "\n",
    "Your model should consists of:\n",
    "* An Embedding layer with 200 embedding dimension. Use `nn.Embedding`.\n",
    "* A Positional embedding layer to include position information for each token. Use the given `PositionalEncoding` Module we took from [this tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html) (recommend reading).\n",
    "* A self-attention layer with 4 heads and 0.3 dropout rate. Use `nn.MultiheadAttention`.\n",
    "* A fully connected layer to map the attention based representation to 400 dimension hidden states. Use `nn.Linear`.\n",
    "* A fully connected layer to map the ***first step*** of the hidden states to the prediction output, use the sigmoid activation for the output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # from https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    def __init__(self, embedding_dim, dropout=0.1, max_len=max_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#ToDo: Fill the __init__() and forward() functions. Add arguments if needed.\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, ):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhewMTrrQm0_",
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len ):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim=200)\n",
    "        self.pos_encoding = PositionalEncoding(embedding_dim=200, max_len = max_len)\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=200, num_heads=4, dropout=0.3, batch_first=True)\n",
    "        self.full_1 = nn.Linear(in_features=200, out_features=400)\n",
    "        self.full_2 = nn.Linear(in_features=400, out_features=1)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        embs = self.embed(x)\n",
    "        pos_encs = self.pos_encoding(embs)\n",
    "        outp, weights = self.self_attention(pos_encs, pos_encs, pos_encs)\n",
    "        full_1 = self.full_1(outp)\n",
    "        full_2 = self.full_2(full_1[:,0,:])\n",
    "        pred = self.sigm(full_2).flatten()\n",
    "        return pred, weights\n",
    "    \n",
    "for test_item in test_set:\n",
    "    TC = TransformerClassifier(len(vocabulary), max_length)\n",
    "    print(TC(torch.tensor([[vocabulary[token] for token in text_tokenizer(test_item[1])]])))\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train the model and evaluate it\n",
    "\n",
    "You don't need to re-implement a training loop if you implemented the one above generally enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#ToDo: Train the model and evalute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "TC = TransformerClassifier(len(vocabulary), max_length)\n",
    "loss_function = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(TC.parameters())\n",
    "train(25, TC, loss_function, optimizer, train_dataloader, val_dataloader, 10, 'TC') \n",
    "print(evaluate(TC, test_dataloader, loss_function)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualize or print the attention scores\n",
    "\n",
    "For the sample sentence: `This is a good movie` visualize the attention scores. A heatmap is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "sample = 'This is a good movie'\n",
    "\n",
    "#ToDo: visualize the attention scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "sample = 'This is a good movie'\n",
    "tokens = text_tokenizer(sample)\n",
    "token_ids = torch.tensor([[vocabulary[token] for token in tokens]])\n",
    "pred, att = TC(token_ids)\n",
    "att = att.detach().squeeze(0).numpy()\n",
    "pred = pred.detach().item()\n",
    "print(f'Prediction: {pred:.3f}, {\"pos\" if pred>0.5 else \"neg\"}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "# from https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the heatmap\n",
    "im = ax.imshow(att, cmap='Blues')\n",
    "\n",
    "    # Create colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel('Attention', rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "ax.set_xticks(np.arange(att.shape[1]))\n",
    "ax.set_yticks(np.arange(att.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "ax.set_xticklabels(tokens)\n",
    "ax.set_yticklabels(tokens)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Create white grid.\n",
    "ax.set_xticks(np.arange(att.shape[1]+1)-.5, minor=True)\n",
    "ax.set_yticks(np.arange(att.shape[0]+1)-.5, minor=True)\n",
    "ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "\n",
    "threshold = im.norm(att.max())/2.\n",
    "\n",
    "# Loop over the data and create a `Text` for each \"pixel\".\n",
    "# Change the text's color depending on the data.\n",
    "texts = []\n",
    "for i in range(att.shape[0]):\n",
    "    for j in range(att.shape[1]):\n",
    "\n",
    "        im.axes.text(j, i, f\"{att[i,j]:.2f}\", color=('black' if int(im.norm(att[i, j]) < threshold) else 'white'),\n",
    "                            horizontalalignment='center', verticalalignment='center')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "9_Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python DL-LAI",
   "language": "python",
   "name": "python-dl_lai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
